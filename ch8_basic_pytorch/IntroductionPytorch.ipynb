{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroductionPytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6qo6cTIRa8ai",
        "jIK2dCrQ2iwQ"
      ],
      "authorship_tag": "ABX9TyOxTSyNzKtMDUEK/U6KZ+gP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesley34/comp3414_course_material/blob/master/ch8_basic_pytorch/IntroductionPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LDiVuxiw9q_",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch basic : in working-process , not complete version\n",
        "\n",
        "\n",
        "*   It is a very easy starter-kit\n",
        "*   I hope you can do it step-by-step\n",
        "*   It is only suitable for 0-experience student\n",
        "*   Feel free to skip if you know pytorch  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7cwVnLpCe-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxavptB6w8_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basically you will need this for most of the time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7js3Lktx1fw",
        "colab_type": "text"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "*   we define our model structure inside nn.sequential\n",
        "*   if you make spliting, you cannot use nn.Sequential \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNScLk6IxLwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(10,5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5,1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrtQKYldx-dX",
        "colab_type": "text"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhCna4oNxsKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f9a12d98-9cdb-4888-fe51-9a02fe9046c4"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU-YBuGqyHBD",
        "colab_type": "text"
      },
      "source": [
        "## Use pre-trained model\n",
        "\n",
        "\n",
        "*   import torchvison\n",
        "*   we use vgg16 as example\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag6hy08LxtJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "fc80d3c4-f563-4175-9362-c2fbfeeda0c8"
      },
      "source": [
        "from torchvision import models\n",
        "model = models.vgg16()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZdeJC50ySZA",
        "colab_type": "text"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "*   batch\n",
        "*   epoches\n",
        "*   learning rate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFrjIEkByOfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Hyperparamter\n",
        "BATCH_SIZE = 3\n",
        "EPOCHS = 200\n",
        "LEARNING_RATE = 3e-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4PRaWzwz8sK",
        "colab_type": "text"
      },
      "source": [
        "## Create Fake data\n",
        "\n",
        "\n",
        "*   Auto-driving cars , the data will be the images from the environment\n",
        "*   But, we will make some fake number to be data first\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh7-PMYc0IiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width = 32\n",
        "height = 32 # photo size is 32*32\n",
        "channel = 3 # RGB channels, so channel size =3\n",
        "# there are 500 photos \n",
        "fake_cat_photo = np.random.random([500,channel,width,height])\n",
        "# there are 500 tags if the cat is real , real == 0 , fake == 1\n",
        "fake_is_cat = np.random.randint(0,2,size=[500,1])\n",
        "# all our data is randomly generated so the model must not be accurate\n",
        "# this is just the example for understanding pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbt6sHEj1uBU",
        "colab_type": "text"
      },
      "source": [
        "## Define a CNN model\n",
        "\n",
        "\n",
        "*   CNN is very useful for doing image stuff\n",
        "*   Many concepts are there, and there are a lot resources that are very good\n",
        "*   I will not teach any CNN here, please watch it yourself or maybe later\n",
        "\n",
        "---\n",
        "Useful Video\n",
        "\n",
        "*   https://www.youtube.com/watch?v=f0t-OCG79-U \n",
        "\n",
        "---\n",
        "\n",
        "Useful reading material\n",
        "\n",
        "*   https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html\n",
        "*   https://en.wikipedia.org/wiki/Convolution , MATH1851 touch a little bit\n",
        "*   https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Useful photo\n",
        "\n",
        "*   https://miro.medium.com/max/700/1*52JnBGMb29SuwbtS8DQlAw.png\n",
        "*   https://cs231n.github.io/assets/nn1/neuron_model.jpeg\n",
        "\n",
        "---\n",
        "In Chinese\n",
        "\n",
        "*   https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC5-1%E8%AC%9B-%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1%E4%BB%8B%E7%B4%B9-convolutional-neural-network-4f8249d65d4f\n",
        "*   https://medium.com/@chih.sheng.huang821/%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-convolutional-neural-network-cnn-cnn%E9%81%8B%E7%AE%97%E6%B5%81%E7%A8%8B-ecaec240a631\n",
        "*   https://www.youtube.com/watch?v=f0t-OCG79-U \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDHz1-2nJwi_",
        "colab_type": "text"
      },
      "source": [
        "## CheckList\n",
        "\n",
        "\n",
        "1.   Convolutional operation\n",
        "2.   Common activation in cnn\n",
        "3.   What is strides?\n",
        "4.   What is kernel(filter)?   \n",
        "5.   What is padding ?\n",
        "6.   How to calculate the result matrix (Tensor) size after cnn   \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "## Answer\n",
        "\n",
        "\n",
        "1.   That mathmatical formula \n",
        "2.   Leaky ReLU, ReLu, Sigmoid ,Tanh\n",
        "3.   How many steps to move the kernel(filter) to do convolution with the data(picture)\n",
        "4.   They will be converged to some speical feature photo to help the machine to detect feature (say, the kernel may converge to a dog-ear to help if the image is dogs)\n",
        "5.   Add some 0 bit to our photo. One of the advantages is that we can use this method to allow more infomation inside our photo to pass the CNN. Consider that : strides is 2 , kernel_size is 3 , photo_width is 4, so the kernel can only move once in the photo, hence kernel-column-4 data cannot be scan. But if we add padding 0 at the end, photo_wight is 5, column-4 data can be scanned.\n",
        "6.   [(Width - kernel_height + 2Padding) / Strides] + 1 , [(Height - kernel_height + 2Padding) / Strides]  + 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrQVqiD21ooc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv = nn.Sequential(\n",
        "    nn.Conv2d(3,10,kernel_size=5,stride=2),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(10,20,kernel_size=4,stride=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(20,50,kernel_size=4,stride=1),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMzLiiSp2JHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "9ab7cf05-f5b0-4057-db4d-19c38c7f0658"
      },
      "source": [
        "print(conv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 10, kernel_size=(5, 5), stride=(2, 2))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (3): ReLU()\n",
            "  (4): Conv2d(20, 50, kernel_size=(4, 4), stride=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ864J6MQPUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qo6cTIRa8ai",
        "colab_type": "text"
      },
      "source": [
        "## Other basic operation inside CNN\n",
        "\n",
        "\n",
        "---\n",
        "The core part is Convolutional nerual network, but we also need other parts to boost its ability.\n",
        "\n",
        "\n",
        "*   Max Pooling \n",
        "    *   Get the biggest bit-value inside the region\n",
        "    *   What is the meaning of region ? check those photo now!\n",
        "    *   But some research said it is bad to the model in some suitation, you go to explore it if you free\n",
        "*   Batch-normalization\n",
        "    *   normalization  method\n",
        "    *   Do normalization on a batch to help preventing gradient exploding or diminish. It can make our model become healthy\n",
        "    *   But some research said it is useless or even harms the model, you go to explore it if you free\n",
        "*   Flatten layer\n",
        "    *   it uses to transform the dimension , from 4D (batch,width,height,channel) -> 2D (batch,width * height * channel) for Linear layer input as linear takes 2D data\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Related Link\n",
        "*   Max pooling\n",
        "  *   https://computersciencewiki.org/index.php/Max-pooling_/_Pooling\n",
        "*   Batch Normalization\n",
        "  *   https://en.wikipedia.org/wiki/Batch_normalization\n",
        "\n",
        "*   Normalization methods, but usually we use the method inside normal distribtuion or min-max scaling\n",
        "  *   https://en.wikipedia.org/wiki/Normalization_(statistics)\n",
        "\n",
        "---\n",
        "There are max pooling, min pooling, average pooling as well: getting highest, loweset and the sample_mean\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIHfFHhibOYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev7rhDjXd4H0",
        "colab_type": "text"
      },
      "source": [
        "## Build a better CNN\n",
        "\n",
        "\n",
        "*   do not use max pooling so much, it is not good indeed\n",
        "*   do not use so much batch-norm , it is also not good indeed\n",
        "*   Suitable-use can yield some betterments\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "General speaking\n",
        "\n",
        "\n",
        "*   Tanh > sigmoid > leaky relu > relu (output)\n",
        "*   vice versa for the performance\n",
        "*   The lite-est activation relu is proven to be the highest-cp in general\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4G7swoweHze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "better_cnn = nn.Sequential(\n",
        "    nn.Conv2d(3,10,kernel_size=5,stride=2),\n",
        "    nn.LeakyReLU(2e-3),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(10,20,kernel_size=4,stride=1),\n",
        "    nn.Tanh(),\n",
        "    nn.Conv2d(20,30,kernel_size=3,stride=1),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(30,1e-05),\n",
        "    nn.Flatten()\n",
        ")\n",
        "\n",
        "def checkDimension(shape):\n",
        "  batch_size = shape[0]\n",
        "  channe_width_height_size = shape[1:]\n",
        "  o = better_cnn(torch.zeros(batch_size,*channe_width_height_size)) # Flattened from 4D -> 2D\n",
        "  return int(np.prod(o.size())) # if o.size == (2,3,4) | np.prod(o.size) == (2*3*4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbmXmdZ1i6nT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1808fc9c-e3d0-4254-838f-8c20ffdd0c53"
      },
      "source": [
        "input_shape = [BATCH_SIZE,channel,width,height]\n",
        "flatten_size = checkDimension(input_shape)\n",
        "print(flatten_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN3bAR7igBiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "bf26573f-c5b9-4323-b756-9263e15ad11e"
      },
      "source": [
        "fully_connected_layer =  nn.Sequential(\n",
        "    nn.Linear(flatten_size,int(flatten_size/2)),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(int(flatten_size/2),int(flatten_size/4)),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(int(flatten_size/4),int(flatten_size/8)),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(int(flatten_size/8),1)\n",
        ")\n",
        "print(fully_connected_layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=360, out_features=180, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=180, out_features=90, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Linear(in_features=90, out_features=45, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=45, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEIzOpPorHje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def net(data):\n",
        "  output_data = better_cnn(data)\n",
        "  predicted_value = fully_connected_layer(output_data)\n",
        "  return predicted_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g6G9OfrrYkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df0f9623-c217-4556-d2a6-6a2f33c01b5a"
      },
      "source": [
        "# make our data input to be pytorch type\n",
        "fake_cat_photo_torch = torch.FloatTensor(fake_cat_photo)\n",
        "print(fake_cat_photo_torch.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([500, 32, 32, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIK2dCrQ2iwQ",
        "colab_type": "text"
      },
      "source": [
        "#### However, if we use function to write our model, it will make our code becomes harder in later part , and we should write in class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZWaHdKv2iP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module): #extend -> we can get the parameter of all layer in a elegent way later if we write in class\n",
        "  def __init__(self,input_shape):\n",
        "    super(CNN,self).__init__();\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "    nn.Conv2d(3,10,kernel_size=5,stride=2),\n",
        "    nn.LeakyReLU(2e-3),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(10,20,kernel_size=4,stride=1),\n",
        "    nn.Tanh(),\n",
        "    nn.Conv2d(20,30,kernel_size=3,stride=1),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(30,1e-05),\n",
        "    nn.Flatten()\n",
        "    )\n",
        "    flatten_size = self.checkDimension(input_shape)\n",
        "    self.fully_connected_layer =  nn.Sequential(\n",
        "    nn.Linear(flatten_size,int(flatten_size/2)),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(int(flatten_size/2),int(flatten_size/4)),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(int(flatten_size/4),int(flatten_size/8)),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(int(flatten_size/8),1)\n",
        "    )\n",
        "\n",
        "  def checkDimension(self,shape):\n",
        "    print(\"Input shape\")\n",
        "    batch_size = shape[0]\n",
        "    channel_width_height_size = shape[1:]\n",
        "    o = better_cnn(torch.zeros(batch_size,*channel_width_height_size)) # Flattened from 4D -> 2D\n",
        "    print(o.size())\n",
        "    print(o.size()[1:])\n",
        "    print(\"flatten_size is\",int(np.prod(o.size()[1:])))\n",
        "    return int(np.prod(o.size()[1:])) # if o.size == (2,3,4) | np.prod(o.size) == (2*3*4)\n",
        "    \n",
        "  # override forward method, if you call CNN outside , it will run this method automatically\n",
        "  def forward(self,x):\n",
        "    flatten_data = self.conv(x)\n",
        "    predict = self.fully_connected_layer(flatten_data)\n",
        "    return predict\n",
        "    \n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSsx9PtM34Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcfDqz24reed",
        "colab_type": "text"
      },
      "source": [
        "## Start train the model . It must be not accurate as we just make up some fake data and tags\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "The common approach is to repeat the following steps\n",
        "\n",
        "1.   get prediction\n",
        "2.   calculate the loss\n",
        "3.   optimizer\n",
        "4.   update (backpropagation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngy4oDyu5k-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFCZPZ6Y5xey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "469c5e19-f1a7-494a-a8e6-2c98aa130a92"
      },
      "source": [
        "net = CNN([BATCH_SIZE,3,32,32])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5996b892a4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'CNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGbWn7ur5O-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net(torch.zeros([3,3,32,32]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Is7Zqvf7Uih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ2Tsxr27UnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kqvaw4Lwf0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define optimizer , what algorithm do we use in gradient descent,\n",
        "# check out the intution of gradient descent is enough\n",
        "optimizer = optim.Adam(lr=LEARNING_RATE,params=net.parameters()) # <-- we use classes hence we can just type net.params, otherwise we need to upstack and concat the params\n",
        "loss_function = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyi3TxR-w1E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ8a25K87tWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(fake_cat_photo.shape) # fake photo size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-VxVArx7t7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u68fs5v_7vLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(BATCH_SIZE) # our batch size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1l_SlFb7xaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjwr9p087xoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# so we need the data snapshot becomes batch_size,channel,width,height,\n",
        "# but how?\n",
        "# dun worry if you do not understand , as the real problem there are no such things."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNM1zHHLxRhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## make a data generator\n",
        "def dataGenerator(datas_x,datas_y,number_of_set = 200, batch_size = BATCH_SIZE):\n",
        "  x_batch = []\n",
        "  y_batch = []\n",
        "  for _ in range(number_of_set*batch_size):\n",
        "    random_number = np.random.randint(0,165,1)[0]\n",
        "    x = datas_x[random_number]\n",
        "    y = datas_y[random_number]\n",
        "    x_batch.append(x)\n",
        "    y_batch.append(y)\n",
        "    if len(x_batch)==batch_size:\n",
        "      yield [x_batch,y_batch]\n",
        "      x_batch = []\n",
        "      y_batch = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrZbzrvCBuW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH5imbq5B3ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_data = list(dataGenerator(fake_cat_photo,fake_is_cat))\n",
        "data_x = []\n",
        "data_y = []\n",
        "for x,y in combined_data:\n",
        "  data_x.append(x)\n",
        "  data_y.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HEZD0K-D6-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array(data_x)\n",
        "y = np.array(data_y)\n",
        "print(x.shape) # number of set, batches,channel,width,height\n",
        "print(y.shape) # number of set, batches,target_size , target size is 1 , it stores 1 or 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAlvgEXK8CuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I5xjR7pASTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you can change it to gpu inside colab , by changing run time\n",
        "device = \"cpu\"\n",
        "x_tensor = torch.FloatTensor(x).to(device)\n",
        "y_tensor = torch.FloatTensor(y).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXYQ0ZdAAnPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test zone , it will be useful if you do not understand how the data structure is\n",
        "print(x_tensor[0].shape)\n",
        "print(y_tensor[0].shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAF5GzXGE-8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(x_tensor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR0ZvcUv8DJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to seperate training data\n",
        "# for more , it is just checking how well is the training data , in real practise especially data science ,\n",
        "# we need train,test,validation set\n",
        "for i in range(EPOCHS):\n",
        "  random_int = np.random.randint(0,165,1)[0]\n",
        "  predict = net(x_tensor[i])  # use our model to ouput the predicition\n",
        "  loss = loss_function(predict,y_tensor[i]) # calculate norm-2 error a.k.a mse mean square error\n",
        "  loss.backward() # backward popagation -> update the weighting inside the model\n",
        "  optimizer.step() # update the optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4fAmBrB8oUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMbtcLo3_lNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## test \n",
        "test_combined_data = list(dataGenerator(fake_cat_photo,fake_is_cat))\n",
        "test_data_x = []\n",
        "test_data_y = []\n",
        "for x,y in test_combined_data:\n",
        "  test_data_x.append(x)\n",
        "  test_data_y.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHQudE-hMYPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tensor_test = torch.FloatTensor(test_data_x).to(\"cpu\")\n",
        "y_tensor_test = torch.FloatTensor(test_data_y).to(\"cpu\")\n",
        "loss_array = []\n",
        "for i in range(200):\n",
        "  predict = net(x_tensor_test[i])\n",
        "  loss = loss_function(predict,y_tensor_test[i])\n",
        "  loss_array.append(loss.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2sNBAKRMvNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(loss_array).mean()\n",
        "# summary\n",
        "# mean loss is 3 \n",
        "# our target are only yes/no , 0 and 1\n",
        "# that means the mean of (prdicted-real)^2 is 3\n",
        "# the error is quite large\n",
        "# because our image data are generated from the distribution by np.random.random()\n",
        "# our image category(yes/no) are also generated from the distribution by np.random.randint()\n",
        "# suppose 2 should be iid -> independent -> no relationship ( covariance should be 0 ) between images and tag."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88xqS5Y3MzKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}