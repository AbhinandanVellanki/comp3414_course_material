{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WrapperInGym.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFvhtyk8Dcxe3spd3BCuSe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesley34/comp3414_course_material/blob/master/ch9_basic_reinforcement_learning/WrapperInGym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBDblKvJqQNp",
        "colab_type": "text"
      },
      "source": [
        "## You will learn how to wrap a gym : in working-process , not complete version\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "##### We need to wrap the gym because we want the training become more stable and better to converge.\n",
        "\n",
        "\n",
        "1.   Sometimes you need to hardcode the action for start of the game, like fire the tennis in tennis game as \"Fire in the beginning is a must\".\n",
        "2.   Due to markov property, 1 frame of photo cannot tell a good story to the model, we may need to stack \"K\" frames of photo together for the sake of getting \"physical momentum data\" like the trajectory of tennis or the car.\n",
        "3.   Resize of photo can be done here\n",
        "4.   Reset the gain/loss of the game\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C1-LtCP0YeB",
        "colab_type": "text"
      },
      "source": [
        "## You need the following knowledge before start\n",
        "\n",
        "1.   oop\n",
        "2.   numpy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdDMiV_10Fhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAJpQMoBqNym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you want to edit the color scale of the picture\n",
        "# you need to extends the gym.ObseravtionWrapper for the purpose\n",
        "# you also need to wrtie a overriden observation function \n",
        "class ScaledWrapper(gym.ObservationWrapper):\n",
        "  def observation(self,obs):\n",
        "    return obs/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9WgEfua0e6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now if you make a gym, the observation ,a.k.a picture, will be normalized by 255\n",
        "# create environment\n",
        "wrapped_env = gym.make(\"Pong-v0\")\n",
        "wrapped_env = ScaledWrapper(wrapped_env)\n",
        "\n",
        "env = gym.make(\"Pong-v0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC3GnzG10sH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "outputId": "edcc6de6-4b16-46aa-8ac4-0b72f9d0fb70"
      },
      "source": [
        "# wrapped\n",
        "wrapped_env.reset()\n",
        "action = wrapped_env.action_space.sample()\n",
        "observation,reward,is_done,_ = wrapped_env.step(action)\n",
        "print(observation)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]]\n",
            "\n",
            " [[0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  ...\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]]\n",
            "\n",
            " [[0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  ...\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]\n",
            "  [0.56470588 0.28235294 0.06666667]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  ...\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]]\n",
            "\n",
            " [[0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  ...\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]]\n",
            "\n",
            " [[0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  ...\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]\n",
            "  [0.9254902  0.9254902  0.9254902 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeFXfc4G03xl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "outputId": "70093f5f-df39-463b-cb23-2b37d5b756d7"
      },
      "source": [
        "# raw\n",
        "env.reset()\n",
        "action = env.action_space.sample()\n",
        "observation,reward,is_done,_ = env.step(action)\n",
        "print(observation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[  0   0   0]\n",
            "  [  0   0   0]\n",
            "  [  0   0   0]\n",
            "  ...\n",
            "  [144  72  17]\n",
            "  [144  72  17]\n",
            "  [144  72  17]]\n",
            "\n",
            " [[144  72  17]\n",
            "  [144  72  17]\n",
            "  [144  72  17]\n",
            "  ...\n",
            "  [144  72  17]\n",
            "  [144  72  17]\n",
            "  [144  72  17]]\n",
            "\n",
            " [[144  72  17]\n",
            "  [144  72  17]\n",
            "  [144  72  17]\n",
            "  ...\n",
            "  [144  72  17]\n",
            "  [144  72  17]\n",
            "  [144  72  17]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[236 236 236]\n",
            "  [236 236 236]\n",
            "  [236 236 236]\n",
            "  ...\n",
            "  [236 236 236]\n",
            "  [236 236 236]\n",
            "  [236 236 236]]\n",
            "\n",
            " [[236 236 236]\n",
            "  [236 236 236]\n",
            "  [236 236 236]\n",
            "  ...\n",
            "  [236 236 236]\n",
            "  [236 236 236]\n",
            "  [236 236 236]]\n",
            "\n",
            " [[236 236 236]\n",
            "  [236 236 236]\n",
            "  [236 236 236]\n",
            "  ...\n",
            "  [236 236 236]\n",
            "  [236 236 236]\n",
            "  [236 236 236]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v3c_fCL1D7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXALBfDk4Ln5",
        "colab_type": "text"
      },
      "source": [
        "### Example\n",
        "\n",
        "#### stack the picture together "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJMeZlGZ7HyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWjbHNjT4TaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# super initializes takes env\n",
        "# \n",
        "class ProcessFrameSize84(gym.ObservationWrapper):\n",
        "  def __init__(self,env=None):\n",
        "    super(ProcessFrameSize84,self).__init__(env)\n",
        "    self.observation_space = gym.spaces.Box(low=0,high=255,shape=(84,84,1),dtype=np.uint8)\n",
        "\n",
        "  # override method\n",
        "  # as the outside => obs,reward,game_end,_ = env.step(action) => obs will get the return from observation\n",
        "  # env.step(action) will call the super observation function\n",
        "  def observation(self,obs):\n",
        "    return ProcessFrameSize84.process(obs)\n",
        "  \n",
        "  # static method \n",
        "  @staticmethod\n",
        "  def process(frame):\n",
        "    if frame.size == 210 * 160 * 3:\n",
        "      image = np.reshape(frame,[210,160,3]).astype(np.float32)\n",
        "    elif frame.size == 250 * 160 * 3:\n",
        "      image = np.reshape(frame,[250,160,3]).astype(np.float32)\n",
        "    else:\n",
        "      assert False, \"Unknown Resolution\"\n",
        "    \n",
        "    # recall biology or physics, green color is more sensitive\n",
        "    # so the weighting is higher\n",
        "    # and the weighting for RGB , the sum of them equals 1\n",
        "    image = image[:,:,0] * .299 + image[:,:,1] * .587 + image[:,:,2] * .114\n",
        "    resized_screen = cv2.resize(image,(84,110),interpolation=cv2.INTER_AREA)\n",
        "    x_t = resized_screen[18:102,:] # cut head and tail\n",
        "    x_t = np.reshape(x_t,[84,84,1])\n",
        "    return x_t.astype(np.uint)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YNdlQRS7uif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrapped_env = gym.make(\"Pong-v0\")\n",
        "wrapped_env = ProcessFrameSize84(wrapped_env)\n",
        "wrapped_env = ScaledWrapper(wrapped_env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeTdbAiW8FBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a94b26b-394f-41b1-bc47-bfd7feb980d3"
      },
      "source": [
        "# wrapped\n",
        "wrapped_env.reset()\n",
        "action = wrapped_env.action_space.sample()\n",
        "observation,reward,is_done,_ = wrapped_env.step(action)\n",
        "print(len(observation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyINa_Mp84OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrapped_env.reset()\n",
        "action = wrapped_env.action_space.sample()\n",
        "observation,reward,is_done,_ = wrapped_env.step(action)\n",
        "print(len(observation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1g5nmos5JaJ",
        "colab_type": "text"
      },
      "source": [
        "## For more\n",
        "https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w98xeXfe5MNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}