{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "em-routing capsnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+vItNrekdoTzBbVqz0zIl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesley34/comp3414_course_material/blob/master/ch11_python_Tensorflow_2.0/em_routing_capsnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpeQZXBbVJsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8edb6223-14af-4586-a211-82a290b1e033"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3sKcnYimEc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRaYxUMvmjDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers,models,Model,Input,regularizers\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wKprIH1mLrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scope 1\n",
        "def scope_1(shape):\n",
        "  input = Input(batch_size=batch_size,shape=shape,name=\"First_Block_Input\")\n",
        "  output = layers.Conv2D(A,[5,5],strides=2,padding=\"VALID\",activation=\"relu\",name=\"First_block_CNN_1\")(input)  # None,28,28,5\n",
        "  data_size = int(np.floor(shape[0]-5+1)/2) # None,12,12,32\n",
        "\n",
        "  model = Model(inputs=input,outputs=output,name=\"Scope_1\")\n",
        "  data_shape = [data_size,data_size,A]\n",
        "  return model,data_shape"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heEE45AgtjuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91UbV0EMtpD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZSKJO1XoWd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scope 2\n",
        "def scope_2 (shape_0,shape_1,shape_2): # usually shape_0 == shape_1 , shape_2 is output channel\n",
        "  shape = [shape_0,shape_1,shape_2]\n",
        "  input = Input(batch_size=batch_size,shape=shape,name=\"Second_Block_Input\")\n",
        "\n",
        "  pose = layers.Conv2D(B*16,[1,1],name=\"Second_Block_CNN_1\")(input) #None,28,28,8*16\n",
        "  pose = tf.reshape(pose,[batch_size,shape_0,shape_1,B,16],\"Second_Block_Reshape_1\") #None,28,28,8,16\n",
        "\n",
        "  activated = layers.Conv2D(B,[1,1],activation=\"sigmoid\",name=\"Second_Block_CNN_2\")(input) #None,28,28,8\n",
        "  activated = tf.reshape(activated,[batch_size,shape_0,shape_1,B,1])  #None,28,28,8,1\n",
        "  \n",
        "  #concated\n",
        "  output = tf.concat([pose,activated],axis=4,name=\"Second_Block_CNN_Plus_Activation\") #None,28,28,8,17\n",
        "  output = tf.reshape(output,[batch_size,shape_0,shape_1,-1],\"Second_Block_Reshape_1\") #None,28,28,8*17\n",
        "\n",
        "  model = Model(inputs=input,outputs=output,name=\"Scope_2\")\n",
        "  data_size = [shape_0,shape_1,8*17]\n",
        "  return model,data_size\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YbPLf_4wr-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scope conv_caps 1\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pS92AiJxbk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE1V68gVxdaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_kernel_tile(input_shape,kernel_size,stride,name):\n",
        " \n",
        "  input = Input(shape=input_shape,batch_size=batch_size,name=\"Input_\"+name) #None,28,28,8*17\n",
        "  input_channel = input_shape[2] # input_shape = None,28,28,8*17\n",
        "  # input ch is input_shape[2], output ch is kernel*kernel\n",
        "  tile_filter = np.zeros([kernel_size,kernel_size,input_shape[2],kernel_size*kernel_size],dtype=np.float32) #3,3,,8*17,3*3\n",
        "\n",
        "  for i in range(kernel_size):\n",
        "    for j in range(kernel_size):\n",
        "      tile_filter[i,j,:,i*kernel_size+j]=1.0 # set different [1] in 9 different filter -> for making different perspectives when youu do matmul over the input\n",
        "      #kernel_size=3,strides=2\n",
        "\n",
        "  tile_filter_op = tf.constant(tile_filter,dtype=tf.float32)# cast to tf and note that this is constant\n",
        " \n",
        "  output = tf.nn.depthwise_conv2d(input,tile_filter_op,strides=[1,stride,stride,1],padding=\"VALID\") #None,28,28,8*17 * 3,3,8*17,3*3 =>(None, 13, 13, 1224)\n",
        "\n",
        "  output = tf.reshape(output,shape=[batch_size,output.shape[1],output.shape[2],input_channel,kernel_size*kernel_size]) #None,13,13,8*17,3*3\n",
        "\n",
        "  output = tf.transpose(output,perm=[0,1,2,4,3]) #None,13,13,3*3,8*17\n",
        "\n",
        "  model = Model(inputs=input,outputs=output,name=name+\"_kernel_tile\")\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZphvJfDcoQ8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmkvzW3ta29K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def variable_with_regularizer(shape,element_size,initializer,regularizer,name):\n",
        "  w = initializer # use this to make some variable\n",
        "  w = tf.map_fn(fn=lambda t: regularizer(t), elems=tf.reshape(w,[element_size,1]),name=name+\"_regularized_l2_w\") # make them outside so I can regularize all \n",
        " \n",
        "  w = tf.reshape(w,shape,name=name+\"_mat_trasform_w_reshape\") # reshape into w_shape\n",
        "  return w"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2iCIzm6BP8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mat_transform(pose_shape,caps_num_c,regularizer,name,tag=False):\n",
        "  #input_shape == None*13*13,3*3*8,16 first conv_caps_layer as example\n",
        "  #caps_num_c == votes_shape # output_dim = vote_dim == ABCD\n",
        "  #caps_num_i = 3,3*3*B B=8\n",
        "  new_batch = pose_shape[0]\n",
        "  input_shape = pose_shape[1:]\n",
        "  input = Input(batch_size=new_batch,shape=input_shape,name=name+\"_mat_transform_input\") # batch_size*13*13,3*3*8,16\n",
        "  caps_num_i = pose_shape[1] #3*3*B\n",
        "  ##\n",
        "  \n",
        "  output = tf.reshape(input,[new_batch,caps_num_i,1,4,4],name=name+\"_mat_trasform_output_reshape\") #batch_size*13*13,3*3*8,1,4,4\n",
        "  output = tf.tile(output,[1,1,caps_num_c,1,1],name=name+\"_mat_trasform_output_tile\") #batch_size*13*13,3*3*8,A/B/C/D,4,4\n",
        "  ##\n",
        "  w_shape = [1,caps_num_i,caps_num_c,4,4] # weighting shape == 1,3*3*A/B/C/D,A/B/C/D,4,4\n",
        "  element_size = 1*caps_num_i*caps_num_c*4*4\n",
        "  ##\n",
        "  initializer = tf.random.truncated_normal(shape=w_shape)\n",
        "  regularizer = tf.keras.regularizers.L2(5e-4)\n",
        "  w = variable_with_regularizer(w_shape,element_size,initializer,regularizer,name)\n",
        "  w = tf.tile(w,[new_batch,1,1,1,1],name=name+\"_mat_trasform_w_tile\") #new_batch_size,3*3*A/B/C/D,A/B/C/D,4,4\n",
        "  ##\n",
        "  votes = tf.reshape(output@w,[new_batch,caps_num_i,caps_num_c,16],name=name+\"_votes\") # #new_batch_size,3*3*A/B/C/D,A/B/C/D,16 as input_shape\n",
        "  model = Model(inputs=input,outputs=votes,name=name+\"_mat_transform\")\n",
        "  return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNS7VM51RRph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def em_routing(votes,activation,new_batch_size,caps_num_i,caps_num_c,n_channels,regularizer,name,tag=False):\n",
        "  # vote shape == #new_batch_size,3*3*A/B/C/D,A/B/C/D,16  #new_batch_size,3*3*8,8,16\n",
        "  # acitvation_shape == #new_batch_size*13*13,3*3*8,1\n",
        "  # new_batch_size = activation_shape[0]\n",
        "  # caps_num_i = activation_shape[1] #\n",
        "  # n_channels = votes_shape[-1] #16\n",
        "\n",
        " \n",
        "\n",
        "  print(\"caps_num_c : {}, n_channels : {}\".format(caps_num_c,n_channels))\n",
        "  # set up initializer\n",
        " \n",
        "  sigma_square = []\n",
        "  miu = []\n",
        "  activation_out = []\n",
        "  ###\n",
        "  beta_v_shape = [caps_num_c,n_channels] #a/b/c/d,16 ==> 8,16\n",
        "  beta_v_element_size = caps_num_c*n_channels\n",
        "  beta_v = variable_with_regularizer(beta_v_shape,beta_v_element_size, tf.constant(0,tf.float32,shape=beta_v_shape),regularizer,name+\"_beta_v\")\n",
        "  ###\n",
        "\n",
        "  beta_a = variable_with_regularizer([caps_num_c],caps_num_c,tf.constant(0,tf.float32,shape=caps_num_c),regularizer,name+\"_beta_a\") #caps_num_c ==> 8\n",
        "\n",
        "  \n",
        "  votes_in = votes\n",
        "  activation_in = activation\n",
        "\n",
        "  for iters in range(iter_routing):\n",
        "    if iters == 0:\n",
        "      r = tf.constant(np.ones([new_batch_size,caps_num_i,caps_num_c])/caps_num_c,tf.float32,name=name+\"_r\") # r == batch_size*13*13,3*3*8,8\n",
        "    else:\n",
        "      log_p_c_h = -tf.math.log(tf.sqrt(sigma_square)) - (tf.square(votes_in-miu)/ (2*sigma_square)) ##batch_size*13*13,3*3*8,8,16\n",
        "      log_p_c_h -= tf.reduce_max(log_p_c_h,axis=[2,3],keepdims=True) - tf.math.log(10.0) ##batch_size*13*13,3*3*8,1,1 => ##batch_size*13*13,3*3*8,8,16(boardCast)\n",
        "      p_c = tf.exp(tf.reduce_sum(log_p_c_h,axis=3)) ##batch_size*13*13,3*3*8,8\n",
        "      ap = p_c * tf.reshape(activation_out,shape=[new_batch_size,1,caps_num_c]) ## batch_size*13*13,3*3*8,8 * batch_size*13*13,1,8=> batch_size*13*13,3*3*8,8 * batch_size*13*13,,3*3*8,8(board_cast) => batch_size*13*13,,3*3*8,8\n",
        "      r = ap/(tf.reduce_sum(ap,axis=2,keepdims=True)+epsilon) #..todo batch_size*13*13,3*3*8,8,16\n",
        "\n",
        "    r = r*activation_in #batch_size*13*13,3*3*8,8,1\n",
        "    r = r/(tf.reduce_sum(r,axis=2,keepdims=True)+epsilon) #batch_size*13*13,3*3*8,1 \n",
        "    r_sum = tf.reduce_sum(r,axis=1,keepdims=True) #batch_size*13*13,1,8 \n",
        "    r1 = tf.reshape(r/(r_sum+epsilon),shape=[new_batch_size,caps_num_i,caps_num_c,1]) # #batch_size*13*13,3*3*8,8,1\n",
        "    miu = tf.reduce_sum(votes_in*r1,axis=1,keepdims=True) #new_batch_size*13*13,3*3*8,8,16 * batch_size*13*13,3*3*8,8,16(boardcasted) => batch_size*13*13,1,8,16=>batch_size*13*13,3*3*8,8,16\n",
        "    sigma_square = tf.reduce_sum(tf.square(votes_in-miu)*r1,axis=1,keepdims=True)+epsilon #batch_size*13*13,1,8,16 => #batch_size*13*13,3*3*8,8,16(boardcasted)\n",
        "    \n",
        "    if iters == iter_routing-1:\n",
        "      r_sum = tf.reshape(r_sum,[new_batch_size,caps_num_c,1]) #batch_size*13*13,3*3*8,8,1 => batch_size*13*13,8,1 #since keepdim => can squeeze like this\n",
        "      cost_h = (beta_v+tf.math.log(tf.sqrt(tf.reshape(sigma_square,shape=[new_batch_size,caps_num_c,n_channels])))) * r_sum  #  batch_size*13*13,8,16(sigma_square) * batch_size*13*13,8,1 => batch_size*13*13,8,16\n",
        "      activation_out = tf.nn.softmax(ac_lambda0*(beta_a-tf.reduce_sum(cost_h,axis=2))) # ..todo new_batch_size,8,16 => new_batch_size,8,1(redcue_sum)\n",
        "    else:\n",
        "      activation_out = tf.nn.softmax(r_sum) ##batch_size*13*13,3*3*8,8,16\n",
        "  \n",
        "\n",
        "  return miu,activation_out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2deNPIVwVEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calEm(input_pose,input_activation,pose_shape,activation_shape,votes_output_dim,weights_regularizer,name):\n",
        "  new_batch_size,caps_num_i = input_pose.shape[:2]\n",
        "  # caps_num_c == votes_output_dim\n",
        "  # pose shape  #None*13*13,3*3*8,17\n",
        "  # calculation on voting\n",
        "  ## model 1\n",
        "  mat_transform_model = mat_transform(pose_shape,votes_output_dim,weights_regularizer,name=name)\n",
        "  \n",
        "  votes = mat_transform_model(input_pose)\n",
        "  ## model 2\n",
        "  # vote shape ==  # #new_batch_size*13*13,3*3*A/B/C/D,A/B/C/D,16 \n",
        "  # acitvation_shape == #new_batch_size*13*13,3*3*8,1\n",
        "  caps_num_c = votes_output_dim\n",
        "  n_channels = votes.shape[-1]\n",
        "  miu,activation = em_routing(votes,input_activation,new_batch_size,caps_num_i,caps_num_c,n_channels,weights_regularizer,name=name)\n",
        "\n",
        "  return miu,activation\n",
        " \n",
        "  \n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3b2nUBRwWjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u39vc14vvxao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import gc\n",
        "# gc.collect()\n",
        "# input_pose = np.ones([10*13*13,3*3*8,16])\n",
        "# input_activation = np.ones([10*13*13,3*3*8,1])\n",
        "# v,e = calEm(input_pose,input_activation,[10*13*13,3*3*8,16],[10*13*13,3*3*8,1],8,tf.keras.regularizers.l2(5e-4),\"try\") "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGdEXF5ZlOgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_caps(input,input_shape,kernel_size,stride,output_dim,weights_regularizer,name):\n",
        "  # output_dim = vote_dim == ABCD\n",
        "  # define kernel_tile_model\n",
        "  kernel_tile_model = build_kernel_tile(input_shape[1:],kernel_size,stride,name)\n",
        " \n",
        "  # output from kernel_tile_model\n",
        "  output = kernel_tile_model(input) #None,13,13,3*3,8*17\n",
        "  \n",
        "  data_size = input_shape[1]\n",
        "  data_size = int(np.floor(data_size-kernel_size+1)/stride)\n",
        " \n",
        "  new_batch = batch_size * data_size * data_size #None*13*13\n",
        "  # make it easier to cut the tensors into 2 part\n",
        "\n",
        "  output = tf.reshape(output,shape=[new_batch,-1,17]) #None*13*13,3*3*8,17\n",
        "  activation = tf.reshape(output[:,:,16],[new_batch,-1,1]) #None*13*13,3*3*8,1\n",
        "  # output[:,:,:16] is pose of last layer\n",
        "  # activation is last layer activation\n",
        "\n",
        "  #calEm(input_pose,input_activation,[10*13*13,3*3*8,16],[10*13*13,3*3*8,1],8,tf.keras.regularizers.l2(5e-4),\"try\") \n",
        "  #mat_transform_model,em_routing_model = calEM(output.shape[:,:,:16],activation.shape,output_dim,weights_regularizer,name) #output shape is #None*13*13,3*3*8,16\n",
        "  pose = output[:,:,:16]\n",
        "  \n",
        "  miu,activation = calEm(pose,activation,pose.shape,activation.shape,output_dim,weights_regularizer,name)\n",
        "\n",
        "  #pose\n",
        "  pose = tf.reshape(miu,[batch_size,data_size,data_size,output_dim,16])\n",
        "  activation = tf.reshape(activation,[batch_size,data_size,data_size,output_dim,1])\n",
        "\n",
        "  \n",
        "  return pose,activation"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xceZFQzFAkQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUoB32p4_buc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_caps_1(output_from_primary_caps,weights_regularizer):\n",
        "  input = layers.Input(batch_size=batch_size,shape=output_from_primary_caps.shape[1:])\n",
        "  pose,activation = conv_caps(input,output_from_primary_caps.shape,3,2,C,weights_regularizer,\"conv_caps_1_conv\")\n",
        "  data_size = pose.shape[1]\n",
        "  output = tf.reshape(tf.concat([pose,activation],axis=4),[batch_size,data_size,data_size,C*17])\n",
        "  model = Model(inputs=[input],outputs=[output],name=\"conv_caps_1\")\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm6-Fn_cAIri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzua6u5CErwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_caps_2(output_from_primary_caps,weights_regularizer):\n",
        "  input = layers.Input(batch_size=batch_size,shape=output_from_primary_caps.shape[1:])\n",
        "  pose,activation = conv_caps(input,output_from_primary_caps.shape,3,1,D,weights_regularizer,\"conv_caps_1_conv\")\n",
        "  data_size = pose.shape[1]\n",
        "  #class caps\n",
        "  pose = tf.reshape(pose,[batch_size*3*3,D,16])\n",
        "  activation = tf.reshape(activation,[batch_size*3*3,D,-1])\n",
        "  miu,activation = calEm(pose,activation,pose.shape,activation.shape,num_classes,weights_regularizer,\"conv_caps_2\")\n",
        "  activation = tf.reshape(activation,[batch_size,data_size,data_size,num_classes])\n",
        "  miu = tf.reshape(miu,[batch_size,data_size,data_size,-1])\n",
        "  output = tf.nn.avg_pool(activation,ksize=[1,data_size,data_size,1],strides=[1,1,1,1],padding=\"VALID\")\n",
        "  output = tf.reshape(output,[batch_size,num_classes])\n",
        "  pose = tf.nn.avg_pool(miu,ksize=[1,data_size,data_size,1],strides=[1,1,1,1],padding=\"VALID\")\n",
        "  pose_out = tf.reshape(pose,shape=[batch_size,num_classes,16])\n",
        "  model = Model(inputs=[input],outputs=[output,pose_out],name=\"conv_caps_2\")\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iaizRqUEuYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFxbHPF0IOhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_vLeODmHrPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spread_loss(output,pose_out,x,y,m):\n",
        "\n",
        "  data_size = x.shape[1]\n",
        "  y = tf.one_hot(y,num_classes,dtype=tf.float32)\n",
        "\n",
        "  reshape_output = tf.reshape(output,[tf.shape(y)[0],1,num_classes])\n",
        "\n",
        "  y = tf.expand_dims(y,axis=2)\n",
        "\n",
        "  at = reshape_output@y\n",
        "\n",
        "  loss = tf.square(tf.maximum(0.,m-(at-reshape_output)))\n",
        "  loss = loss@(1.-y)\n",
        "  loss = tf.reduce_mean(loss)\n",
        "\n",
        "  pose_out = tf.reshape(tf.multiply(pose_out,y),shape=[batch_size,-1])\n",
        "\n",
        "  model = models.Sequential(\n",
        "      [\n",
        "       layers.Dense(512,trainable=True,kernel_regularizer=tf.keras.regularizers.l2(5e-4)),\n",
        "       layers.Dense(1024,trainable=True,kernel_regularizer=tf.keras.regularizers.l2(5e-4)),\n",
        "       layers.Dense(data_size*data_size,trainable=True,kernel_regularizer=tf.keras.regularizers.l2(5e-4),activation=\"sigmoid\")\n",
        "      ]\n",
        "  )\n",
        "  pose_out = model(pose_out)\n",
        "  x = tf.reshape(x,shape=[tf.shape(y)[0],-1])\n",
        "  reconstruction_loss = tf.reduce_mean(tf.square(pose_out-x)) #6800 - 25??\n",
        "  loss_all = tf.add_n([loss]+[0.0005*data_size*data_size*reconstruction_loss])\n",
        "  return loss_all,reconstruction_loss,pose_out\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEdiBWz-WPpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNMeayq3WPnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_accuracy(logits,labels):\n",
        "  \n",
        "  logits_index = tf.cast((tf.argmax(logits,axis=1)),tf.int32)\n",
        "  \n",
        "  #logits_index = tf.reshape(logits_index,labels.shape[0])\n",
        "  #labels = tf.reshape(labels,labels.shape[0])\n",
        "\n",
        "  correct_preditions = tf.equal(tf.cast(labels,tf.int32),logits_index)\n",
        "  accuracy =tf.reduce_sum(tf.cast(correct_preditions,tf.float32)) / tf.cast(tf.shape(labels)[0],tf.float32)\n",
        "  return accuracy,logits_index"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbRvbm9jSeSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  #input 1 \n",
        "  input = Input(shape=[28,28,1],batch_size=batch_size)\n",
        "  batch_x_squash = tf.divide(input,255.)\n",
        "  batch_x = layers.BatchNormalization(center=False,trainable=True)(batch_x_squash) \n",
        "  #input 2\n",
        "  batch_labels = Input(shape=[],batch_size=batch_size)\n",
        "\n",
        "  #model start\n",
        "  model_1, data_size_1 = scope_1(shape=[28,28,1])\n",
        "  model_2, data_size_2 = scope_2(*data_size_1)\n",
        "  model_3 = conv_caps_1(model_2.output,weights_regularizer)\n",
        "  model_4 = conv_caps_2(model_3.output,weights_regularizer)\n",
        "  \n",
        "  x = model_1(batch_x)\n",
        "  x = model_2(x)\n",
        "  x = model_3(x)\n",
        "\n",
        "  output,pose_out = model_4(x)\n",
        "\n",
        " \n",
        "  \n",
        "  batch_labels_casted = tf.cast(batch_labels,tf.int32)\n",
        "  \n",
        "  #loss,_,_ = spread_loss(output,pose_out,batch_x_squash,batch_labels_casted,m)\n",
        "\n",
        "\n",
        "  model = Model(inputs=[input,batch_labels],outputs=[output,pose_out,batch_x_squash],name=\"EM_Routing_capsnet\")\n",
        "  #accuracy,logits_index = test_accuracy(output,batch_labels_casted)\n",
        "\n",
        "  return model\n",
        " "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnhrezDnDyKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(model,input,batch_labels):\n",
        "  output,pose_out,batch_x_squash = model(input)\n",
        "  loss,_,_ = spread_loss(output,pose_out,batch_x_squash,batch_labels,m)\n",
        "  return loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXCZifwb9IRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad(model, inputs, batch_labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs,batch_labels)\n",
        "  return loss_value, tape.gradient(loss_value,model.trainable_variables)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uySPqCPwIDuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYZtewkdIDrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "0e1448e5-9afd-43f4-a27a-a1d79cdeaf4d"
      },
      "source": [
        "import os\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.77.202.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.77.202.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4nlLvx0Dx2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3t0ncu-Txo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_min = 0.2\n",
        "m_max = 0.9\n",
        "m = m_min\n",
        "decay_steps = 1000\n",
        "decay_rate = 0.8\n",
        "##HYPERPERAMETER\n",
        "weight_reg = False\n",
        "epsilon = 1e-9\n",
        "iter_routing = 2\n",
        "A,B,C,D = 32,8,16,1 #each layers output channel dim\n",
        "batch_size = 5000\n",
        "num_classes = 10\n",
        "ac_lambda0 = 0.01\n",
        "weights_regularizer = tf.keras.regularizers.l2(5e-4)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOG3QYktwtxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9_iaZrbT19A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my0d6R1Y-A5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nctJndL9vk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train,y_train),(X_test,y_test)=tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAXenjmR-Ajg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nn4JfOu-fOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_df(X,y):\n",
        "  y = np.int32(y)\n",
        "  X = np.float32(X)\n",
        "  X_expanded = np.expand_dims(X,3)\n",
        "  X_tf = tf.data.Dataset.from_tensor_slices(X_expanded)\n",
        "  y_tf = tf.data.Dataset.from_tensor_slices(y)\n",
        "  total_tf = tf.data.Dataset.zip((X_tf,y_tf))\n",
        "  df = total_tf.repeat().batch(batch_size)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agb-OVt--fTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset  = get_df(X_train,y_train)\n",
        "test_dataset  = get_df(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nF0dkE2_8yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jbBhdHtEqqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIk0FofMErin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(1e-3,decay_steps=decay_steps,end_learning_rate=1e-5)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi82nWL_1PMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## training start\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "num_epochs = 201\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  # Training loop - using batches of 32\n",
        "  for x, y in train_dataset:\n",
        "    loss_value,grads = grad(model,x,y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    epoch_loss_avg(loss_value)\n",
        "    output,_,_ = model(x)\n",
        "    epoch_accuracy(y,output)\n",
        "\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,epoch_loss_avg.result(),epoch_accuracy.result()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shhlV1i5EsK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsR_pjH6Etog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}