{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroductionDL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOME+zT/o8eH4Rad5W9rf21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesley34/comp3414_course_material/blob/master/ch6_basic_deepLearning/IntroductionDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Orszz5su1i9",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning introduction : in working-process , not complete version\n",
        "\n",
        "\n",
        "*   it is designed for completely zero-experience user in deep learning\n",
        "*   Intuitional idea will be given\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2fvRbF2vlTC",
        "colab_type": "text"
      },
      "source": [
        "## Assumption\n",
        "\n",
        "\n",
        "*   you already know a little bit numpy\n",
        "*   you know some oop\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-4n1gQzvBrf",
        "colab_type": "text"
      },
      "source": [
        "## You will learn\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*   basic concept in deep learning\n",
        "*   basic tensorflow\n",
        "*   basic pytorch\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV50wUKXvVIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIsrQVflvWI_",
        "colab_type": "text"
      },
      "source": [
        "## Section 1 : basic concept in deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59M7oQoBv99y",
        "colab_type": "text"
      },
      "source": [
        "## 3 component of deep learning\n",
        "\n",
        "\n",
        "*   data\n",
        "*   model\n",
        "*   prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLV_xzodvZpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a39938f-5930-4abf-f027-8a1f1ca4b73d"
      },
      "source": [
        "# example 1, demonstrate the 3 elements\n",
        "# a model predict tmr have rain or not base on today\n",
        "today_data = \"rain\"\n",
        "model = lambda x : x == \"rain\"\n",
        "# if u dk lambda\n",
        "# def model(x):\n",
        "#   if x==\"rain\"\n",
        "#     return True\n",
        "#   return False\n",
        "\n",
        "prediction = model(today_data)\n",
        "print(\"Tomorrow will have rain is\", prediction)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tomorrow will have rain is True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88qnAwdMwYA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "62c7708a-20f2-4843-b8e9-ec978cedaacb"
      },
      "source": [
        "# example 2, demonstrate the 3 elements by predicting the best-fitted line\n",
        "# we will not discuss regression here\n",
        "# no need to care what sklearn is doing\n",
        "# just skip it :>\n",
        "# and know it is magic is enough\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# now you want to predict the best-fitted line\n",
        "\n",
        "## we make x = 3 as matrix form , then we add some noise to it, as to simulate that our data to be real one\n",
        "x = np.ones([50,1],dtype=np.float32)\n",
        "# print(x)\n",
        "noise = np.random.random([50,1])\n",
        "\n",
        "x = x + noise\n",
        "# print(noise)\n",
        "y = 3 * x + 9\n",
        "# print(noise)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "# model.fit(x,y) means train the x and let x approximate to y\n",
        "\n",
        "trained_model = model.fit(x,y)\n",
        "\n",
        "## print(training_fit.coef_,training_fit.intercept_)\n",
        "print(\"the slope predicted is\", training_fit.coef_[0][0])\n",
        "print(\"the intercept is\", training_fit.intercept_[0] )\n",
        "# good it can predict y = 3x + 9 from noisy data :>\n",
        "print(\"it can predict the equation y = 3x + 9 in nosiy data\")\n",
        "\n",
        "# if you know from data science approach,\n",
        "# it maybe feel something weird as I put trained result as prediction analysis\n",
        "# but I just use this to demonstrate the concept of model."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the slope predicted is 3.0000000000000004\n",
            "the intercept is 8.999999999999998\n",
            "it can predict the equation y = 3x + 9 in nosiy data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA9arZQN0PzB",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "1.   X wants to approximate Y\n",
        "2.   We need to tell the model how long the distance is from x to y\n",
        "3.   We use loss function, we calcuate the loss and send to the model\n",
        "4.   the error sent to the model , the model itself will anaylsis the data and self-correct\n",
        "5.   the common loss function is mean square error = (prediction-real)^2\n",
        "6.   if prediction is 1000 , real is 0 , then the error will be 1000000. This error will send to model, and model will anaysis itself.\n",
        "7.   please ignore how the prediction come from this model, if you don't know as it is not important here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XClH__n8w-SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV3FNSaS1Och",
        "colab_type": "text"
      },
      "source": [
        "## Deep learning\n",
        "###### if you feel there are many word, you may look at the code first\n",
        "\n",
        "1.   Loss function (to calculate how much our model is wrong) is still mean square in common\n",
        "2.   The prediction process is done by 2 elements in common. Matrix multiplication and activation function\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Matrix multiplication\n",
        "\n",
        "\n",
        "*   X is size of n * h , W is size of h * K , XW is the size of n * K\n",
        "*   Usually we would like our data input times a weighting, and you usually do not know what's the actual meaning behind X * Weight. (Indeed you will know, Let's assume you don't know)\n",
        "*   W can also known as the line\n",
        "*   Weigthing will be change with time as when the model predict wrongly, the model will edit the weights.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Activation function\n",
        "\n",
        "\n",
        "*   Activation function can demonstrate no linearity or filter the data, (linear means y = ax + b, a straight line). You know the problem will not be finding a best-fitted line anymore \n",
        "*   Example of activation function : tanh(data input) , the data enter this function will become non-linear.\n",
        "*   Example of activation function : ReLU(data input), the data smaller than 0 will be filter out, otherwise keep it.\n",
        "*   Many activation function will be use, usually we will use activation function after matrix multiplication\n",
        "*   Activation function can also known as the neurons\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Deep Learning flow\n",
        "\n",
        "\n",
        "1.   You need data , model and loss function\n",
        "2.   for model, you will assign randomly for the number of layers\n",
        "3.   each layers we will have some number of neurons\n",
        "4.   each layers are connected with lines\n",
        "5.   then you pass your data -> they will flow inside the model (repeat matrix multiplication and activation) -> the output will appear in final neurons layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My1WJUxC6PDD",
        "colab_type": "text"
      },
      "source": [
        "##### before watch the code, please search some pictures from google, you observe the photo and see there are some lines and some circles(neurons)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z5hWR7TxZJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# libaray for Deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# nn means neural network\n",
        "# nn.Sequential is called when you make the model, and you put every thing inside\n",
        "# nn.Sequential cannot be use if you make a split inside the model (free to skip this sentence if u dun understand)\n",
        "\n",
        "# create model , it is called net\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(10,20),  # nn.Linear(input_size,weight_size) , in this case input_size = ? * 10, the weighting size will be 10*20 => XW = ?*20\n",
        "    nn.Tanh(), # follow by activation function Tanh(XW) , size == ?*20\n",
        "    nn.Linear(20,10), # input_data size == ?*20 , weighting == 20*10, size of Data*W => ?*20*20*10 ==> ?*10\n",
        "    nn.Tanh(), # follow by activation tanh(XW), size ?*10\n",
        "    nn.Linear(10,1) # the output size is one , input_data size = ?*10 , weighing == 10*1 => XW size == ?*1\n",
        ")\n",
        "# so it return the data size == ?*1\n",
        "# where ? is the size of batch\n",
        "# batch is how many data_x you want the model to calcuate at the same time.\n",
        "# people loves inputing a batch or data instead of 1-singel data at the same time for the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhHgx_Hc4snA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create data\n",
        "## use this noisy data again\n",
        "## x = (1+noise)\n",
        "## y = 3x + 9\n",
        "x = np.ones([50,1],dtype=np.float32) # x size 50 * 1 , weight for first layer size is 10 * 20 , bug will occur later , you may try to keep running\n",
        "# print(x)\n",
        "noise = np.random.random([50,1])\n",
        "\n",
        "x = x + noise\n",
        "# print(noise)\n",
        "y = 3 * x + 9\n",
        "\n",
        "###############\n",
        "# dun look it as data-science apprach\n",
        "# no split, no cross-validation ... again it is intro :>\n",
        "# you need to make it to pytorch-style data-structure\n",
        "x_data = torch.FloatTensor(x)\n",
        "y_data = torch.FloatTensor(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHOVNQAg6xLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "2c4039db-d3db-4aca-e9b9-9b1a25736c5f"
      },
      "source": [
        "# create prediction\n",
        "# this will bug , think about why \n",
        "prediction = net(x_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-1214ce46c8fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this will bug , think about why\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [50 x 1], m2: [10 x 20] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsYz8_p89c16",
        "colab_type": "text"
      },
      "source": [
        "#### Correct data creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eKz5_0b7JvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create data\n",
        "## use this noisy data again\n",
        "## x = (1+noise)\n",
        "## y = 3x + 9\n",
        "x = np.ones([50,10],dtype=np.float32) # x size 50 * 10 , weight size is 10 * 20\n",
        "# print(x)\n",
        "noise = np.random.random([50,10])\n",
        "\n",
        "x = x + noise\n",
        "# print(noise)\n",
        "y = 3 * x + 9\n",
        "\n",
        "###############\n",
        "# dun look it as data-science apprach\n",
        "# no split, no cross-validation ... again it is intro :>\n",
        "# you need to make it to pytorch-style data-structure\n",
        "x_data = torch.FloatTensor(x)\n",
        "y_data = torch.FloatTensor(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50I90v7X8NbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create prediction\n",
        "# this will bug , think about why \n",
        "prediction = net(x_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL68LDti8OmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa5b67cc-ceae-4592-8dfb-03ab134b6658"
      },
      "source": [
        "print(prediction.mean()) #not 12? , y should be 3*(1+noise)+9 ~= 3+9 = 12 , 0.2469 is wrong !!!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-0.2787, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbk__3sg9gC4",
        "colab_type": "text"
      },
      "source": [
        "#### start to make our model better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPpXwLu8pPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# so now we need to tell the model : \"You are wrong\", but how?\n",
        "# we need create_loss function , mse stands for mean-square-error\n",
        "loss_function  = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1so37y-98Wf",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent\n",
        "#### Although i dun want to talk any math here, it must talk some here\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   You have some loss but how can you tell the model?\n",
        "*   You need to have another 3 elements again\n",
        "*   optimizer, backward-propagation and clear gradient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cv7BxIY-iua",
        "colab_type": "text"
      },
      "source": [
        "## Check some 2D graph here ,\n",
        "#### https://www.google.com/search?q=gradient+descent&client=firefox-b-d&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiZz_Giit_rAhUSPXAKHYO6DoAQ_AUoAXoECBYQAw&biw=1600&bih=825\n",
        "\n",
        "1.   We have a 2d graph , y is loss \n",
        "2.   We want to find the min loss , so we find the lowest point\n",
        "3.   Minimum loss means the value will become more accurate\n",
        "4.   The point of min denote as (x * , y * ) , x * will become the most suitable number as weighting. \n",
        "5.   X is a vector, representing a set of weights.\n",
        "6.   How to find the min point given that we are now in 100-Dimension space?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NL4N66h_4Vc",
        "colab_type": "text"
      },
      "source": [
        "## Solution : gradient descent\n",
        "###### gradient means slope, that means you take (partial) derivative on the loss function y , a.k.a tangent\n",
        "\n",
        "1.   Imagine 2D case, to make thing simple\n",
        "2.   Draw tangent at our current point\n",
        "3.   the tangent direction can lead us to the lower staircase, you can try to draw a tangent at the current point\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dZFspW6AOX7",
        "colab_type": "text"
      },
      "source": [
        "Solution : gradient descent with learning rate\n",
        "\n",
        "\n",
        "1.   we need to specify how the man will walk given that you have the direction now\n",
        "2.   if you place safe , you can walk 1 step\n",
        "3.   if you do not afraid from any risk, you can walk 100000 steps to that direction every time\n",
        "4.   learning rate means how much step you want to walk if you have the direction from tangent.\n",
        "5.   Hence, if you make the leanring rate so small, it will become an old-man, walk very slowly to the best-point(minimun point), but if you make is so large like 100000 steps, you may skip the best-point :<\n",
        "6.   So, you need to make a suitable learning rate\n",
        "7.   Bare-in-mind, the point x will keep changing, a.k.a the network weighting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnuK74V-9bOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we use adam , which is a magic - algorithm that helps us to reach the solution point\n",
        "# note that, it maybe a local minima :>\n",
        "# it is not a magic indeed , you can check yourself , i just want to provide a good start to 0-exp people.\n",
        "\n",
        "optimizer = optim.Adam(lr=1e-2,params=net.parameters()) # you will need to provide the parameter inside the model ,\n",
        "                               # as they can change the value of the weighting W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB3-7bXD9xp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f7f40840-d59c-4049-d320-9ef54d665a06"
      },
      "source": [
        "# in your training loop:\n",
        "epoches = 500\n",
        "# epcohes means how many time you want to walk at the graph\n",
        "# if you walk a little steps , you may not get the optimal solution\n",
        "# if you walk too much , you may overfit the data\n",
        "for _ in range(epoches):\n",
        "  optimizer.zero_grad()   # reset the gradient, as you need to re-draw the tangent line in every epoches\n",
        "  output = net(x_data)\n",
        "  loss = loss_function(output, y_data) # calculate the loss\n",
        "  loss.backward()     # you need this to send (backward propogate) the error to the param, if not, you will bug\n",
        "  optimizer.step()    # Does the update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([50, 10])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu6KE_rIBz-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "outputId": "2315a0b1-b2c0-4107-f9ec-d1aa1c5a6076"
      },
      "source": [
        "# we try to see the result\n",
        "# I make another set of noisy data\n",
        "test_x = np.random.random([50,10])\n",
        "test_x = torch.FloatTensor(test_x)\n",
        "# get the prediction\n",
        "\n",
        "print(net(test_x)) # is it close to 13 , you may add more epoches in for loop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[13.4760],\n",
            "        [13.4602],\n",
            "        [13.4519],\n",
            "        [13.4669],\n",
            "        [13.4498],\n",
            "        [13.4556],\n",
            "        [13.4621],\n",
            "        [13.4267],\n",
            "        [13.4515],\n",
            "        [13.4754],\n",
            "        [13.4785],\n",
            "        [13.4614],\n",
            "        [13.4731],\n",
            "        [13.4674],\n",
            "        [13.4686],\n",
            "        [13.4779],\n",
            "        [13.4613],\n",
            "        [13.4635],\n",
            "        [13.4690],\n",
            "        [13.4354],\n",
            "        [13.4508],\n",
            "        [13.4732],\n",
            "        [13.4706],\n",
            "        [13.4369],\n",
            "        [13.4756],\n",
            "        [13.4686],\n",
            "        [13.4671],\n",
            "        [13.4771],\n",
            "        [13.4491],\n",
            "        [13.4761],\n",
            "        [13.4660],\n",
            "        [13.4713],\n",
            "        [13.4716],\n",
            "        [13.4718],\n",
            "        [13.4354],\n",
            "        [13.4725],\n",
            "        [13.4747],\n",
            "        [13.4641],\n",
            "        [13.4641],\n",
            "        [13.4582],\n",
            "        [13.4554],\n",
            "        [13.4701],\n",
            "        [13.4711],\n",
            "        [13.4592],\n",
            "        [13.4722],\n",
            "        [13.4641],\n",
            "        [13.4572],\n",
            "        [13.4637],\n",
            "        [13.4680],\n",
            "        [13.4461]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAkViINzB6QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxwOqrbzFC2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeQ6gzURFFnt",
        "colab_type": "text"
      },
      "source": [
        "## Check if you know\n",
        "\n",
        "\n",
        "1.   what is weighting\n",
        "2.   what is activation functions\n",
        "3.   what is gradient descent\n",
        "4.   how to update the model (backward propagation)\n",
        "5.   what is loss fucntion does\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHT-K1OOFR0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# quick fast example with both pytorch and tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5QERIDOFXp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "## create model\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(10,5),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(5,3),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(3,1)\n",
        ")\n",
        "\n",
        "## create learning rate and epoches , we call this hyper parameter which is model configuartion\n",
        "learning_rate = 3e-3\n",
        "epoches = 1400\n",
        "\n",
        "## create loss function and optimizer\n",
        "optimizer = optim.Adam(lr=learning_rate,params=net.parameters())\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "# basically no need validation set , test set for duckietown problem so I just simply skip all :> ignore this if you do not understand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPCVVOWcG5jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create data\n",
        "x = np.ones([1,10],dtype=np.float32)*3 + np.random.random([1,10])\n",
        "y = 3 * x + 9\n",
        "\n",
        "tensor_x = torch.FloatTensor(x)\n",
        "tensor_y = torch.FloatTensor(y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqHXRJxlF-XV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "1367bf86-33ae-4d31-b749-1e53c244cde9"
      },
      "source": [
        "## training\n",
        "for _ in range(epoches):\n",
        "  net.zero_grad()\n",
        "  prediction = net(tensor_x)\n",
        "  loss = loss_function(prediction,tensor_y)\n",
        "  loss.backward()\n",
        "  optimizer.step() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([1, 10])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T7XQ5quIcM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a701baf-9f4a-437f-991a-f402365e4bed"
      },
      "source": [
        "## create test data \n",
        "x = np.ones([1,10],dtype=np.float32)*3 + np.random.random([1,10])\n",
        "tensor_x = torch.FloatTensor(x)\n",
        "print(net(tensor_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[14.6944]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj9rIS5VIij4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}